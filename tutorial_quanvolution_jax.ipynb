{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d0e805",
   "metadata": {},
   "source": [
    "# High-Performance Quanvolutional Neural Networks with JAX & Flax\n",
    "\n",
    "**Author:** Spartoons  \n",
    "**Based on:** [PennyLane Quanvolutional Neural Networks Tutorial](https://pennylane.ai/qml/demos/tutorial_quanvolution) (Apache 2.0)\n",
    "\n",
    "## Overview\n",
    "This project is a port of the classic PennyLane \"Quanvolution\" tutorial from TensorFlow/Keras to the **JAX/Flax** ecosystem. \n",
    "\n",
    "The primary goal of this implementation is to demonstrate high-performance quantum simulation by leveraging JAX's **Just-In-Time (JIT) compilation** and **automatic vectorization (`vmap`)**. \n",
    "\n",
    "### Key Improvements\n",
    "* **Vectorized Quantum Execution:** Instead of iterating over image patches with Python loops, we use `jax.vmap` to process all patches in a batch simultaneously.\n",
    "* **JAX/Flax Training Loop:** A custom, stateless training loop allows for fine-grained control over optimization steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a4ef6d",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup\n",
    "We utilize `PennyLane` for quantum circuits, `JAX` for high-performance numerical computing, and `Flax` for building the neural network. `Optax` provides the optimization logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dc8f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import flax.linen as nn\n",
    "from flax.training import train_state\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3938bcf",
   "metadata": {},
   "source": [
    "## 2. Configuration & Hyperparameters\n",
    "**Critical Setup:** We enable JAX 64-bit precision (`jax_enable_x64`). Quantum simulations often require high numerical precision to maintain unitary constraints; running in default 32-bit mode can sometimes lead to numerical instability in gradient calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbaf93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Critical Configuration Setting ---\n",
    "# Enable x64 precision for numerical stability in quantum simulations.\n",
    "jax.config.update(\"jax_enable_x64\", True) \n",
    "\n",
    "# Check available devices. 'gpu' or 'tpu' must be present for acceleration.\n",
    "print(f\"JAX x64 Enabled: {jax.config.read('jax_enable_x64')}\")\n",
    "print(f\"Available JAX devices: {jax.devices()}\")\n",
    "\n",
    "# If you have GPU or TPU and it's not recognize, you should reinstall jaxlib corresponding\n",
    "# to your CUDA Toolkit: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ee9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50   # Number of optimization epochs\n",
    "n_layers = 1    # Number of random layers\n",
    "n_wires = 4     # Number of random wires\n",
    "n_train = 50   # Size of the train dataset\n",
    "n_test = 30    # Size of the test dataset\n",
    "\n",
    "SAVE_PATH = \"../_static/demonstration_assets/quanvolution/\"  # Data saving folder\n",
    "PREPROCESS = True               # If False, skip quantum processing and load data from SAVE_PATH\n",
    "root_key = jax.random.key(0)    # Get key for JAX random number generator\n",
    "\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b208e25",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing\n",
    "We load the MNIST dataset and preprocess it for the hybrid model:\n",
    "1.  **Normalization:** Pixel values are scaled to the [0, 1] range.\n",
    "2.  **Reshaping:** Images are reshaped to add a channel dimension, adhering to the standard (H, W, C) format expected by convolutional logic.\n",
    "3.  **JAX Device Put:** Data is explicitly pushed to the accelerator (GPU/TPU) if available to minimize transfer overhead during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = load_dataset(\"mnist\")\n",
    "mnist_dataset.set_format(type=\"numpy\")\n",
    "\n",
    "# Reduce dataset size\n",
    "train_images = mnist_dataset['train'][:n_train]['image']\n",
    "train_labels = mnist_dataset['train'][:n_train]['label']\n",
    "test_images = mnist_dataset['test'][:n_test]['image']\n",
    "test_labels = mnist_dataset['test'][:n_test]['label']\n",
    "\n",
    "# Normalize pixel values within 0 and 1\n",
    "x_train = jnp.array(train_images, dtype=jnp.float64) / 255.0\n",
    "x_test = jnp.array(test_images, dtype=jnp.float64) / 255.0\n",
    "\n",
    "# Add extra dimension for convolution channels\n",
    "x_train = x_train[..., jnp.newaxis]\n",
    "x_test = x_test[..., jnp.newaxis]\n",
    "\n",
    "# Push to device (GPU/TPU) efficiently\n",
    "x_train = jax.device_put(x_train)\n",
    "y_train = jax.device_put(train_labels)\n",
    "x_test = jax.device_put(x_test)\n",
    "y_test = jax.device_put(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0af830",
   "metadata": {},
   "source": [
    "## 4. The Quantum Circuit (Kernel)\n",
    "This circuit acts as the \"filter\" for our convolution. It takes a small patch of pixel data (embedded via `RY` rotations) and processes it through random quantum layers. The measurement statistics (expectations of Pauli-Z) serve as the new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f783ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=n_wires)\n",
    "\n",
    "# Random circuit parameters\n",
    "root_key, rand_key = jax.random.split(root_key)\n",
    "rand_params = jax.random.uniform(jax.random.key(0), (n_layers, n_wires), maxval=2 * jnp.pi)\n",
    "\n",
    "@qml.qnode(dev, interface=\"jax\")\n",
    "def circuit(phi, weights):\n",
    "    # Encoding of 4 classical input values\n",
    "    for j in range(4):\n",
    "        qml.RY(np.pi * phi[j], wires=j)\n",
    "    \n",
    "    # Random quantum circuit\n",
    "    RandomLayers(weights, wires=list(range(4)))\n",
    "\n",
    "    # Measurement producing 4 classical output values\n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f8c150",
   "metadata": {},
   "source": [
    "## 5. Vectorized Quanvolution Layer (The \"JAX Magic\")\n",
    "This function represents the core performance improvement of this project. \n",
    "\n",
    "In standard implementations, \"quanvolution\" often involves a nested `for` loop that iterates over every 2x2 patch of the image, running the quantum circuit sequentially. This is computationally expensive.\n",
    "\n",
    "**Here, we utilize `jax.vmap`:**\n",
    "1.  We extract all 2x2 patches from the image first.\n",
    "2.  We stack them into a single batch tensor.\n",
    "3.  We apply `jax.vmap(circuit, in_axes=(0, None))` to execute the quantum circuit on **all patches simultaneously**.\n",
    "\n",
    "This transforms an $O(N)$ sequential operation into a single vectorized call, significantly accelerating the preprocessing phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc2e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def quanv_layer(image, weights):\n",
    "    \"\"\"\n",
    "    Performs the quantum convolution fully vectorized over spatial dimensions.\n",
    "    This replaces the slow nested Python loops with a single, fast JAX operation.\n",
    "    \"\"\"\n",
    "    # 1. Generate all top-left coordinates for a 2x2 kernel with stride 2\n",
    "    rows = jnp.arange(0, 28, 2)\n",
    "    cols = jnp.arange(0, 28, 2)\n",
    "    j_grid, k_grid = jnp.meshgrid(rows, cols, indexing='ij')\n",
    "\n",
    "    # Flatten grids to get 196 (j, k) pairs\n",
    "    j_flat = j_grid.flatten()\n",
    "    k_flat = k_grid.flatten()\n",
    "\n",
    "    # 2. Extract all 196 (2x2) patches efficiently, creating a batch for vmap.\n",
    "    # We manually stack the four pixel values for each patch into the feature dimension (axis 1).\n",
    "    patch_features = jnp.stack([\n",
    "        image[j_flat, k_flat, 0],\n",
    "        image[j_flat, k_flat + 1, 0],\n",
    "        image[j_flat + 1, k_flat, 0],\n",
    "        image[j_flat + 1, k_flat + 1, 0]\n",
    "    ], axis=1) # Shape is (196, 4)\n",
    "\n",
    "    # 3. Vectorize the quantum circuit application over the batch dimension (axis 0).\n",
    "    # in_axes=(0, None) means the first argument (phi/patches) is batched, \n",
    "    # and the second argument (weights) is fully replicated.\n",
    "    vectorized_circuit = jax.vmap(circuit, in_axes=(0, None))\n",
    "    \n",
    "    # The batched circuit returns results of shape (196, 4)\n",
    "    q_results_list = vectorized_circuit(patch_features, weights)\n",
    "\n",
    "    # Stack the list of 4 output arrays into a single (196, 4) array\n",
    "    q_results_batched = jnp.stack(q_results_list, axis=-1)\n",
    "\n",
    "    # 4. Reshape the 196 linear results back to the (14, 14, 4) output shape\n",
    "    out = q_results_batched.reshape((14, 14, 4))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99949532",
   "metadata": {},
   "source": [
    "### âš¡ Performance Analysis: vmap vs. Loops\n",
    "Here, we demonstrate the efficiency gain. We benchmark our vectorized `quanv_layer` against a standard nested Python loop implementation on a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76846ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# --- Benchmarking Block ---\n",
    "\n",
    "def quanv_layer_loop(image, weights):\n",
    "    \"\"\"\n",
    "    Standard non-vectorized implementation using loops (for comparison).\n",
    "    \"\"\"\n",
    "    out = np.zeros((14, 14, 4))\n",
    "    # Loop over the 14x14 output grid\n",
    "    for j in range(0, 28, 2):\n",
    "        for k in range(0, 28, 2):\n",
    "            # Extract 2x2 patch\n",
    "            patch = [\n",
    "                image[j, k, 0],\n",
    "                image[j, k + 1, 0],\n",
    "                image[j + 1, k, 0],\n",
    "                image[j + 1, k + 1, 0]\n",
    "            ]\n",
    "            # Convert to tensor for circuit\n",
    "            q_results = circuit(jnp.array(patch), weights)\n",
    "            \n",
    "            # Map grid coordinates to output indices\n",
    "            out_j, out_k = j // 2, k // 2\n",
    "            out[out_j, out_k] = q_results\n",
    "            \n",
    "    return jnp.array(out)\n",
    "\n",
    "print(\"Running Benchmark on 1 sample...\")\n",
    "\n",
    "# 1. Warm-up JIT compilation for the vectorized function\n",
    "dummy_img = x_train[0]\n",
    "_ = quanv_layer(dummy_img, rand_params) \n",
    "\n",
    "# 2. Time Vectorized (JAX vmap)\n",
    "start = time.time()\n",
    "for _ in range(10): # Run 10 times to get stable average\n",
    "    _ = quanv_layer(dummy_img, rand_params).block_until_ready()\n",
    "end = time.time()\n",
    "vmap_time = (end - start) / 10\n",
    "\n",
    "# 3. Time Loop (Standard Python)\n",
    "start = time.time()\n",
    "# Run only once because it's slow!\n",
    "_ = quanv_layer_loop(dummy_img, rand_params) \n",
    "end = time.time()\n",
    "loop_time = (end - start)\n",
    "\n",
    "print(f\"Vectorized (vmap) time: {vmap_time:.4f}s\")\n",
    "print(f\"Standard (loop) time:   {loop_time:.4f}s\")\n",
    "print(f\"Speedup:                {loop_time / vmap_time:.1f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe516a7",
   "metadata": {},
   "source": [
    "## 6. Precomputing Quantum Features\n",
    "Since the quantum circuit parameters are fixed (random) and not trained in this specific transfer-learning architecture, we can pre-calculate the \"quanvolved\" images. This freezes the quantum features, allowing the classical dense network to train rapidly on the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5daa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"Running Benchmark...\")\n",
    "\n",
    "# 1. Comparison Function (Standard Loops)\n",
    "def quanv_layer_loop(image, weights):\n",
    "    out = np.zeros((14, 14, 4))\n",
    "    for j in range(0, 28, 2):\n",
    "        for k in range(0, 28, 2):\n",
    "            patch = [\n",
    "                image[j, k, 0],\n",
    "                image[j, k + 1, 0],\n",
    "                image[j + 1, k, 0],\n",
    "                image[j + 1, k + 1, 0]\n",
    "            ]\n",
    "            # Note: We use the QNode directly here, not the vmapped version\n",
    "            q_results = circuit(jnp.array(patch), weights)\n",
    "            out[j // 2, k // 2] = q_results\n",
    "    return out\n",
    "\n",
    "# 2. Warm-up (Crucial for JAX!)\n",
    "# JAX needs to compile the function the first time it sees it. \n",
    "# We run it once so the compilation time isn't included in the benchmark.\n",
    "dummy_img = x_train[0]\n",
    "_ = quanv_layer(dummy_img, rand_params).block_until_ready()\n",
    "\n",
    "# 3. Benchmark JAX Vmap\n",
    "start = time.time()\n",
    "# Run it 10 or 100 times to get a stable average\n",
    "n_runs = 100\n",
    "for _ in range(n_runs):\n",
    "    # .block_until_ready() forces Python to wait for the GPU/CPU to finish\n",
    "    _ = quanv_layer(dummy_img, rand_params).block_until_ready()\n",
    "end = time.time()\n",
    "vmap_time = (end - start) / n_runs\n",
    "\n",
    "# 4. Benchmark Loop\n",
    "# Loops are slow, so maybe just run 1 or 5 times\n",
    "start = time.time()\n",
    "n_loop_runs = 5\n",
    "for _ in range(n_loop_runs):\n",
    "    _ = quanv_layer_loop(dummy_img, rand_params)\n",
    "end = time.time()\n",
    "loop_time = (end - start) / n_loop_runs\n",
    "\n",
    "print(f\"Vectorized (vmap) time: {vmap_time:.4f}s\")\n",
    "print(f\"Standard (loop) time:   {loop_time:.4f}s\")\n",
    "print(f\"Speedup:                {loop_time / vmap_time:.1f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7d2ea",
   "metadata": {},
   "source": [
    "### Visualizing the Quantum Features\n",
    "Below we compare the original input images (top row) with the 4 output channels generated by the quantum circuit. Notice how the quantum layer acts as a feature extractor, highlighting different edges and patterns depending on the random weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66362a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 4\n",
    "n_channels = 4\n",
    "fig, axes = plt.subplots(1 + n_channels, n_samples, figsize=(10, 10))\n",
    "for k in range(n_samples):\n",
    "    axes[0, 0].set_ylabel(\"Input\")\n",
    "    if k != 0:\n",
    "        axes[0, k].yaxis.set_visible(False)\n",
    "    axes[0, k].imshow(x_train[k, :, :, 0], cmap=\"gray\")\n",
    "\n",
    "    # Plot all output channels\n",
    "    for c in range(n_channels):\n",
    "        axes[c + 1, 0].set_ylabel(\"Output [ch. {}]\".format(c))\n",
    "        if k != 0:\n",
    "            axes[c, k].yaxis.set_visible(False)\n",
    "        axes[c + 1, k].imshow(q_train_images[k, :, :, c], cmap=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd742c9",
   "metadata": {},
   "source": [
    "## 7. Hybrid Model Architecture (Flax)\n",
    "We define a classical fully connected network using **Flax**. This model takes the flattened quantum features as input and outputs logits for the 10 MNIST classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29adaa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the Model (Stateless Architecture)\n",
    "class MyModel(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # Flatten the input: (Batch, Height, Width, Channels) -> (Batch, Features)\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        # Dense layer to 10 classes (Output Logits)\n",
    "        x = nn.Dense(features=10)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981e7ee",
   "metadata": {},
   "source": [
    "## 8. Optimization & Evaluation Steps\n",
    "We define the functional training logic required by JAX:\n",
    "* **`train_step`**: Computes the loss and gradients using `jax.value_and_grad`, then updates the model parameters (`TrainState`) using Optax.\n",
    "* **`eval_step`**: Computes metrics without updating parameters.\n",
    "\n",
    "Both functions are decorated with `@jax.jit` to compile them into optimized XLA kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ecfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch_images, batch_labels):\n",
    "    \"\"\"\n",
    "    Performs a single optimization step.\n",
    "    Calculates loss and gradients, then updates the TrainState.\n",
    "    \"\"\"\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn({'params': params}, batch_images)\n",
    "        # Use softmax_cross_entropy with integer labels (expects logits)\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "            logits=logits, labels=batch_labels\n",
    "        ).mean()\n",
    "        return loss, logits\n",
    "\n",
    "    # Compute gradients and return auxiliary data (logits)\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(state.params)\n",
    "    \n",
    "    # Update state with gradients (Optax optimizer logic applied here)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == batch_labels)\n",
    "    return state, loss, accuracy\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(state, batch_images, batch_labels):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a batch without updating parameters.\n",
    "    \"\"\"\n",
    "    logits = state.apply_fn({'params': state.params}, batch_images)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "        logits=logits, labels=batch_labels\n",
    "    ).mean()\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == batch_labels)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda7c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(rng, input_shape, learning_rate=0.01):\n",
    "    \"\"\"Creates the initial TrainState (parameters + optimizer).\"\"\"\n",
    "    model = MyModel()\n",
    "    # Initialize parameters using a dummy input\n",
    "    params = model.init(rng, jnp.ones(input_shape))['params']\n",
    "    # Define optimizer (Adam)\n",
    "    tx = optax.adam(learning_rate)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=model.apply, params=params, tx=tx\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab28069f",
   "metadata": {},
   "source": [
    "## 9. Custom Training Loop\n",
    "Unlike Keras, Flax requires an explicit training loop. This function manages the epoch iterations, data shuffling, batching, and state updates. It returns the final trained state and a history dictionary for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13bb765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(train_x, train_y, test_x, test_y, epochs, batch_size, rng_seed):\n",
    "    # Data preparation\n",
    "    num_samples = train_x.shape[0]\n",
    "    steps_per_epoch = num_samples // batch_size\n",
    "    input_shape = (1, *train_x.shape[1:]) # (1, H, W, C)\n",
    "    \n",
    "    # Initialize State\n",
    "    rng = jax.random.key(rng_seed)\n",
    "    init_rng, train_rng = jax.random.split(rng)\n",
    "    state = create_train_state(init_rng, input_shape)\n",
    "    \n",
    "    history = {'loss': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle data at start of epoch\n",
    "        train_rng, shuffle_rng = jax.random.split(train_rng)\n",
    "        perms = jax.random.permutation(shuffle_rng, num_samples)\n",
    "        perms = perms[:steps_per_epoch * batch_size] # Skip incomplete batch\n",
    "        \n",
    "        # Reshape for easy batching\n",
    "        epoch_perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "        \n",
    "        batch_losses = []\n",
    "        batch_accs = []\n",
    "\n",
    "        # --- Train Loop ---\n",
    "        for batch_idx in epoch_perms:\n",
    "            batch_imgs = train_x[batch_idx]\n",
    "            batch_lbls = train_y[batch_idx]\n",
    "            state, loss, acc = train_step(state, batch_imgs, batch_lbls)\n",
    "            batch_losses.append(loss)\n",
    "            batch_accs.append(acc)\n",
    "            \n",
    "        # --- Validation Loop ---\n",
    "        # (Eval on full test set at once since it's small, else batch this too)\n",
    "        val_loss, val_acc = eval_step(state, test_x, test_y)\n",
    "        \n",
    "        # Logging\n",
    "        train_loss = np.mean(batch_losses)\n",
    "        history['loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "        \n",
    "        if epoch % 2 == 0: # Print every 5 epochs\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "                  f\"Loss: {train_loss:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} | \"\n",
    "                  f\"Val Acc: {val_acc:.4f}\")\n",
    "            \n",
    "    return state, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1151e6",
   "metadata": {},
   "source": [
    "## 10. Experiment Execution\n",
    "We now train two models for comparison:\n",
    "1.  **Quantum Model:** Trains on the `q_train_images` (features extracted by the quantum circuit).\n",
    "2.  **Classical Model:** Trains on the raw `x_train` images (standard pixel data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training Quantum Model (JAX) ---\")\n",
    "# Note: q_train_images must be generated by the PREPROCESS loop first\n",
    "q_state, q_history = fit_model(\n",
    "    q_train_images, y_train, \n",
    "    q_test_images, y_test, \n",
    "    epochs=n_epochs, batch_size=4, rng_seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a73a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training Classical Model (JAX) ---\")\n",
    "c_state, c_history = fit_model(\n",
    "    x_train, y_train, \n",
    "    x_test, y_test, \n",
    "    epochs=n_epochs, batch_size=4, rng_seed=84\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec51734",
   "metadata": {},
   "source": [
    "## 11. Results & Comparison\n",
    "We plot the validation accuracy and loss for both models. \n",
    "\n",
    "*Note: For this demonstration, we used a very small subset of MNIST (50 samples). As a result, validation metrics may be noisy. In a full-scale scenario, the quantum features often provide distinct learnability advantages or faster convergence in specific regimes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6270c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 9))\n",
    "\n",
    "ax1.plot(q_history[\"val_accuracy\"], \"-ob\", label=\"With quantum layer\")\n",
    "ax1.plot(c_history[\"val_accuracy\"], \"-og\", label=\"Without quantum layer\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(q_history[\"val_loss\"], \"-ob\", label=\"With quantum layer\")\n",
    "ax2.plot(c_history[\"val_loss\"], \"-og\", label=\"Without quantum layer\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_ylim(top=2.5)\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pennyhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
